# File: recaptcha_browser.py
import json
import os
import time
import random
import threading
import requests
from playwright.sync_api import sync_playwright
from .get_proxy import get_proxy_from_api

# --- C·∫§U H√åNH ---
# D√πng ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫°y t·ª´ main.py v·∫´n t√¨m th·∫•y
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
COOKIES_PATH = os.path.join(BASE_DIR, "_internal", "config", "cookies.json")
SITE_KEY = "6LdsFiUsAAAAAIjVDZcuLhaHiDn5nnHVXVRQGeMV"
TARGET_URL = "https://labs.google/fx/tools/flow" # Ho·∫∑c image-fx tu·ª≥ nhu c·∫ßu

# Global proxy rotation state - thread-safe
_proxy_rotation_index = 0
_proxy_keys_cache = []
_proxy_lock = threading.Lock()
# Thread-local storage for proxy assignment
_thread_local = threading.local()

def get_proxy_api_keys():
    """ƒê·ªçc danh s√°ch proxy API keys t·ª´ file proxy.txt (m·ªói d√≤ng m·ªôt key)"""
    global _proxy_keys_cache
    try:
        proxy_file = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "proxy.txt")
        with open(proxy_file, 'r', encoding='utf-8') as f:
            proxy_keys = [line.strip() for line in f.readlines() if line.strip()]
            if proxy_keys:
                _proxy_keys_cache = proxy_keys
                return proxy_keys
            else:
                print("‚ö†Ô∏è [PROXY] File proxy.txt r·ªóng")
                _proxy_keys_cache = []
                return []
    except FileNotFoundError:
        print("‚ö†Ô∏è [PROXY] File proxy.txt kh√¥ng t·ªìn t·∫°i")
        _proxy_keys_cache = []
        return []
    except Exception as e:
        print(f"‚ö†Ô∏è [PROXY] L·ªói ƒë·ªçc file proxy.txt: {e}")
        _proxy_keys_cache = []
        return []

def get_next_proxy_key():
    """L·∫•y proxy key ri√™ng cho t·ª´ng thread - ƒë·∫£m b·∫£o kh√¥ng b·ªã tr√πng"""
    global _proxy_rotation_index, _proxy_keys_cache

    thread_id = threading.current_thread().ident

    with _proxy_lock:
        if not _proxy_keys_cache:
            # Re-read file if cache empty
            get_proxy_api_keys()
            if not _proxy_keys_cache:
                return None

        # M·ªói thread c√≥ proxy key ri√™ng - assign m·ªôt l·∫ßn duy nh·∫•t
        if not hasattr(_thread_local, 'assigned_proxy'):
            # Assign proxy key cho thread n√†y (c√≥ th·ªÉ tr√πng n·∫øu h·∫øt proxy keys)
            proxy_key = _proxy_keys_cache[_proxy_rotation_index]
            _thread_local.assigned_proxy = proxy_key
            _proxy_rotation_index = (_proxy_rotation_index + 1) % len(_proxy_keys_cache)

            print(f"[PROXY] Thread {thread_id} assigned proxy key: {proxy_key[:20]}... (index {_proxy_rotation_index-1})")
        else:
            proxy_key = _thread_local.assigned_proxy
            # Ch·ªâ log khi thread g·ªçi l·∫ßn ƒë·∫ßu, kh√¥ng log c√°c l·∫ßn sau ƒë·ªÉ tr√°nh spam

        return proxy_key

def load_project_cookies():
    if not os.path.exists(COOKIES_PATH):
        # Th·ª≠ t√¨m ·ªü th∆∞ m·ª•c cha n·∫øu ch·∫°y t·ª´ th∆∞ m·ª•c con
        parent_path = os.path.join(BASE_DIR, "_internal", "config", "cookies.json")
        if os.path.exists(parent_path):
            with open(parent_path, 'r', encoding='utf-8') as f: return _parse_cookies(json.load(f))
        return []
    
    try:
        with open(COOKIES_PATH, 'r', encoding='utf-8') as f:
            return _parse_cookies(json.load(f))
    except: return []

def _parse_cookies(data):
    """H√†m ph·ª• tr·ª£ ƒë·ªÉ parse cookies"""
    cookies = []
    for name, info in data.items():
        if isinstance(info, dict):
            c = {
                "name": name, 
                "value": info.get("value"), 
                "domain": info.get("domain"), 
                "path": info.get("path", "/"), 
                "secure": info.get("secure", True)
            }
            if "expiry" in info: c["expires"] = info["expiry"]
            cookies.append(c)
    return cookies

def human_interaction(page):
    """Gi·∫£ l·∫≠p h√†nh vi ng∆∞·ªùi th·∫≠t - random movements v√† cu·ªôn"""
    # ƒê·ª£i ng·∫Øn nh∆∞ ng∆∞·ªùi d√πng ƒëang quan s√°t nhanh
    time.sleep(random.uniform(0.3, 0.8))
    # Random movements trong v√πng ch√¢n browser
    movements = 6  # TƒÉng s·ªë l·∫ßn di chuy·ªÉn

    for _ in range(movements):
        # Random position trong v√πng ch√¢n browser (800-1280 x 500-720)
        target_x = random.randint(800, 1280)
        target_y = random.randint(500, 720)

        # ƒê·∫£m b·∫£o trong viewport
        target_x = max(0, min(target_x, 1280))
        target_y = max(0, min(target_y, 720))

        # Random steps (8-15) v√† speed (0.15-0.4s)
        steps = random.randint(8, 15)
        delay = random.uniform(0.15, 0.4)

        page.mouse.move(target_x, target_y, steps=steps)
        time.sleep(delay)

    # H√†nh vi cu·ªôn gi·ªëng ng∆∞·ªùi: cu·ªôn nhi·ªÅu l·∫ßn v·ªõi pattern t·ª± nhi√™n
    scroll_patterns = [
        (0, 300),   # Cu·ªôn xu·ªëng s√¢u
        (0, 200),   # Cu·ªôn th√™m
        (0, -50),   # Cu·ªôn l√™n ch√∫t (nh∆∞ ƒë·ªçc l·∫°i)
        (0, 400),   # Cu·ªôn s√¢u h∆°n
        (0, 250),   # Cu·ªôn th√™m n·ªØa
    ]

    for scroll_x, scroll_y in scroll_patterns:
        page.mouse.wheel(scroll_x, scroll_y)
        # Th·ªùi gian d·ª´ng gi·ªØa c√°c l·∫ßn cu·ªôn (nh∆∞ ng∆∞·ªùi ƒë·ªçc)
        if scroll_y > 0:  # Cu·ªôn xu·ªëng
            time.sleep(random.uniform(0.8, 1.5))
        else:  # Cu·ªôn l√™n
            time.sleep(random.uniform(0.5, 1.0))

    # Click v·ªõi hesitation (do d·ª± nh∆∞ ng∆∞·ªùi th·∫≠t)
    time.sleep(random.uniform(0.3, 0.7))

    try:
        # Click random trong v√πng ch√¢n browser
        click_x = random.randint(900, 1280)
        click_y = random.randint(550, 720)
        click_x = max(0, min(click_x, 1280))
        click_y = max(0, min(click_y, 720))
        page.click("body", position={"x": click_x, "y": click_y})
    except:
        pass

    # Th√™m hesitation cu·ªëi c√πng
    time.sleep(random.uniform(0.2, 0.5))

# Kh√¥ng c√≤n d√πng global browser instance - m·ªói request t·∫°o browser ri√™ng

def get_proxy_from_api_with_retry(api_key: str) -> str:
    """
    L·∫•y proxy t·ª´ API v·ªõi ƒë·∫ßy ƒë·ªß retry logic bao g·ªìm /current endpoint
    """
    return get_proxy_from_api(api_key)

def _parse_proxy_string(proxy_string: str) -> dict:
    """Parse proxy string th√†nh dict cho Playwright"""
    if not proxy_string:
        return {}

    try:
        # Lo·∫°i b·ªè protocol (http://)
        if proxy_string.startswith('http://'):
            proxy_string = proxy_string[7:]

        # T√°ch username:password@server:port ho·∫∑c server:port
        if '@' in proxy_string:
            auth_part, server_part = proxy_string.split('@', 1)
            username, password = auth_part.split(':', 1)
        else:
            server_part = proxy_string
            username = password = None

        server, port = server_part.split(':', 1)

        proxy_config = {
            'server': f'http://{server}:{port}'
        }

        if username and password:
            proxy_config['username'] = username
            proxy_config['password'] = password

        return proxy_config

    except Exception as e:
        print(f"‚ö†Ô∏è [BROWSER] L·ªói parse proxy string: {e}")
        return {}

def create_browser_instance():
    """
    T·∫°o browser instance m·ªõi cho m·ªói request.
    M·ªói request c√≥ proxy ri√™ng bi·ªát, thread-safe.
    Tr·∫£ v·ªÅ: tuple (page, playwright, browser, context, creation_time)
    """
    print("üöÄ [BROWSER] T·∫°o browser instance m·ªõi cho request...")

    try:
        from playwright.sync_api import sync_playwright

        # L·∫•y proxy ri√™ng cho request n√†y - th·ª≠ t·∫•t c·∫£ proxy keys cho ƒë·∫øn khi t√¨m ƒë∆∞·ª£c proxy ho·∫°t ƒë·ªông
        proxy_string = None
        proxy_keys = get_proxy_api_keys()  # L·∫•y t·∫•t c·∫£ proxy keys

        if not proxy_keys:
            print("‚ùå [BROWSER] Kh√¥ng c√≥ proxy keys ƒë·ªÉ th·ª≠")
            return None, None, None, None, None

        print(f"[BROWSER] Co {len(proxy_keys)} proxy keys, thu lan luot cho den khi tim duoc proxy...")

        # Th·ª≠ t·ª´ng proxy key cho ƒë·∫øn khi t√¨m ƒë∆∞·ª£c proxy ho·∫°t ƒë·ªông
        for i, proxy_key in enumerate(proxy_keys):
            print(f"[BROWSER] Thu proxy key #{i+1}/{len(proxy_keys)}: {proxy_key[:20]}...")
            proxy_string = get_proxy_from_api_with_retry(proxy_key)

            if proxy_string:
                print(f"[BROWSER] Proxy key #{i+1} thanh cong!")
                break
            else:
                print(f"[BROWSER] Proxy key #{i+1} fail, thu proxy tiep theo...")

        if not proxy_string:
            print("‚ùå [BROWSER] T·∫•t c·∫£ proxy keys ƒë·ªÅu fail")
            return None, None, None, None, None

        proxy_config = {}
        if proxy_string:
            proxy_config = _parse_proxy_string(proxy_string)
            if proxy_config:
                print(f"‚úÖ [BROWSER] S·ª≠ d·ª•ng proxy: {proxy_config['server']}")
            else:
                print("‚ö†Ô∏è [BROWSER] Kh√¥ng th·ªÉ parse proxy")
        else:
            print("‚ö†Ô∏è [BROWSER] Kh√¥ng l·∫•y ƒë∆∞·ª£c proxy t·ª´ API")

        playwright = sync_playwright().start()
        browser = playwright.chromium.launch(
            headless=False,  # ƒê·ªÉ False cho Google tin t∆∞·ªüng
            args=["--disable-blink-features=AutomationControlled", "--no-sandbox"]
        )

        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 720},
            proxy=proxy_config if proxy_config else None
        )

        cookies = load_project_cookies()
        if cookies: context.add_cookies(cookies)

        page = context.new_page()

        # Navigate to target URL v·ªõi error handling
        try:
            page.goto(TARGET_URL, timeout=30000)  # Gi·∫£m timeout xu·ªëng 30s
            page.wait_for_timeout(1000)  # Gi·∫£m wait time

            # Ki·ªÉm tra xem page c√≥ load ƒë∆∞·ª£c kh√¥ng
            title = page.title()
            if "ERR_PROXY_CONNECTION_FAILED" in title or "No internet" in title or "proxy server" in title.lower():
                print("‚ùå [BROWSER] Proxy connection failed detected in page title")
                cleanup_browser_instance(playwright, browser, context, page)
                return None, None, None, None, None

            human_interaction(page)

            # ƒê·ª£i ReCAPTCHA load v·ªõi timeout
            page.wait_for_function("() => window.grecaptcha && window.grecaptcha.enterprise", timeout=15000)

        except Exception as nav_error:
            error_msg = str(nav_error)
            print(f"‚ùå [BROWSER] Navigation failed: {error_msg}")

            # Check for proxy-related errors
            if any(keyword in error_msg.lower() for keyword in ["proxy", "connection", "timeout", "network", "err_"]):
                print("üåê [BROWSER] Proxy/network error detected - force cleanup")
                cleanup_browser_instance(playwright, browser, context, page)
                return None, None, None, None, None
            else:
                # Re-raise other errors
                raise nav_error

        creation_time = time.time()
        print(f"‚úÖ [BROWSER] Browser instance m·ªõi ƒë√£ s·∫µn s√†ng! (ID: {creation_time})")

        # Tr·∫£ v·ªÅ tuple (page, playwright, browser, context, creation_time)
        return page, playwright, browser, context, creation_time

    except Exception as e:
        print(f"‚ùå [BROWSER] L·ªói t·∫°o browser instance: {e}")
        return None, None, None, None, None

def cleanup_browser_instance(playwright, browser, context, page):
    """Cleanup browser instance sau khi s·ª≠ d·ª•ng"""
    try:
        if page: page.close()
        if context: context.close()
        if browser: browser.close()
        if playwright: playwright.stop()

        # Thread-local cleanup (proxy indices are maintained per thread)
        print("üßπ [BROWSER] Browser instance ƒë√£ ƒë∆∞·ª£c cleanup")
    except Exception as e:
        print(f"‚ö†Ô∏è [BROWSER] L·ªói cleanup browser: {e}")

def get_captcha_token():
    """
    H√†m ch√≠nh ƒë·ªÉ g·ªçi t·ª´ b√™n ngo√†i.
    T·∫°o browser instance ri√™ng cho m·ªói request v·ªõi timeout 30s.
    M·ªói request ho√†n to√†n ƒë·ªôc l·∫≠p - browser instance, proxy ri√™ng.
    Tr·∫£ v·ªÅ: Chu·ªói Token (String) ho·∫∑c None n·∫øu l·ªói.
    """
    thread_id = threading.current_thread().ident
    print(f"üîÑ [BROWSER] Thread {thread_id}: T·∫°o browser instance v√† l·∫•y Token...")

    # T·∫°o browser instance m·ªõi cho request n√†y
    # Kh√¥ng retry browser creation n·ªØa v√¨ proxy rotation ƒë√£ handle
    page, playwright, browser, context, creation_time = create_browser_instance()

    if not page:
        print("‚ùå [BROWSER] Kh√¥ng th·ªÉ t·∫°o browser instance (t·∫•t c·∫£ proxy keys fail)")
        return None

    try:
        # Ki·ªÉm tra th·ªùi gian t·ªìn t·∫°i tr∆∞·ªõc khi th·ª±c thi
        elapsed_time = time.time() - creation_time
        if elapsed_time > 20:  # Gi·∫£m t·ª´ 30s xu·ªëng 20s
            print(f"‚è∞ [BROWSER] Browser ƒë√£ t·ªìn t·∫°i {elapsed_time:.1f}s > 20s, force cleanup")
            return None

        print(f"‚è±Ô∏è [BROWSER] Browser age: {elapsed_time:.1f}s, proceeding...")

        # Th·ª±c thi l·∫•y token v·ªõi retry logic cho connection errors
        max_retries = 2
        for attempt in range(max_retries):
            try:
                token = page.evaluate(f"""
                    async () => {{
                        return await window.grecaptcha.enterprise.execute('{SITE_KEY}', {{action: 'FLOW_GENERATION'}})
                    }}
                """)

                # Ki·ªÉm tra l·∫°i th·ªùi gian sau khi th·ª±c thi
                total_elapsed = time.time() - creation_time
                if total_elapsed > 20:
                    print(f"‚è∞ [BROWSER] Browser ƒë√£ t·ªìn t·∫°i {total_elapsed:.1f}s > 20s trong qu√° tr√¨nh th·ª±c thi, discarding token")
                    return None

                if token:
                    print(f"‚úÖ [BROWSER] L·∫•y Token th√†nh c√¥ng (D√†i {len(token)} k√Ω t·ª±, Browser age: {total_elapsed:.1f}s)")
                    return token
                else:
                    print("‚ö†Ô∏è [BROWSER] Kh√¥ng nh·∫≠n ƒë∆∞·ª£c token")
                    return None

            except Exception as eval_error:
                error_msg = str(eval_error)
                if any(keyword in error_msg.lower() for keyword in ["connection", "closed", "proxy", "network", "timeout"]):
                    if attempt < max_retries - 1:
                        print(f"üîÑ [BROWSER] Connection/proxy error (attempt {attempt + 1}/{max_retries}), reloading page...")
                        try:
                            # Th·ª≠ reload page
                            page.reload(timeout=8000)
                            page.wait_for_function("() => window.grecaptcha && window.grecaptcha.enterprise", timeout=8000)
                            # Th·ª±c hi·ªán l·∫°i human interaction nh·∫π
                            time.sleep(random.uniform(0.2, 0.5))
                            for _ in range(2):
                                x = random.randint(900, 1200)
                                y = random.randint(600, 720)
                                page.mouse.move(x, y, steps=5)
                                time.sleep(random.uniform(0.1, 0.2))
                            continue
                        except Exception as reload_error:
                            reload_msg = str(reload_error)
                            print(f"‚ö†Ô∏è [BROWSER] Reload failed: {reload_msg}")
                            # N·∫øu reload c≈©ng fail v√¨ proxy, th√¨ ƒë√¢y l√† proxy bad
                            if any(keyword in reload_msg.lower() for keyword in ["proxy", "connection", "network"]):
                                print("üåê [BROWSER] Proxy appears to be bad, will try different proxy on next browser creation")
                                return None  # Force new browser creation with different proxy
                            continue
                    else:
                        print(f"‚ùå [BROWSER] Connection errors persisted after {max_retries} attempts")
                        return None
                else:
                    # Kh√¥ng ph·∫£i connection error, raise l·∫°i
                    raise eval_error

    except Exception as e:
        error_time = time.time() - creation_time
        error_msg = str(e)
        print(f"‚ö†Ô∏è [BROWSER] L·ªói l·∫•y token sau {error_time:.1f}s: {error_msg}")

        # Check for specific connection errors
        if any(keyword in error_msg.lower() for keyword in ["connection", "closed", "timeout", "network"]):
            print("üåê [BROWSER] Detected connection/network error - browser may have been blocked")
        elif "recaptcha" in error_msg.lower():
            print("ü§ñ [BROWSER] ReCAPTCHA related error - may need different approach")

        return None

    finally:
        # Lu√¥n cleanup browser instance sau khi s·ª≠ d·ª•ng
        cleanup_browser_instance(playwright, browser, context, page)

# Kh√¥ng c√≤n c·∫ßn h√†m close_browser_instance v√¨ m·ªói request t·ª± cleanup

# ƒêo·∫°n n√†y ƒë·ªÉ test file n√†y ch·∫°y ƒë·ªôc l·∫≠p
if __name__ == "__main__":
    t = get_captcha_token()
    print("Token test:", t)